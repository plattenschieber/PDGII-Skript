3) \underline{Beh.:}
\[span\{p^{(0)},\dots p^{(k)} \} = span \{ r^{(0)},Ar^{(0)},\dots A^kr^{(0)}\} =: \underbrace{\mathcal{K}_{k+1}(r^{(0)})}_{\text{Krylovraum}} \]
Offensichtlich gilt: $span \{ p^{(0)},\dots p^{(k)}\} =span \{ r^{(0)},r^{(1)},\dots , r^{(k)}\}$\\
\begin{proof}
3) mit vollst. Induktion;\\
IA: da $p^{(0)}=r^{(0)}$ \\
$'\subset '$: IV: $ span \{ p^{(0)},\dots , p^{(k)} \} = \mathcal{K}_{k+1}(r^{(0)}) $\\
IS: IV $\Rightarrow Ap^{(k)} \in \mathcal{K}_{k+2}(r^{(0)})$\\
Aus $(\ast \ast)$ also $r^{(k+1)=r^{(k)-\alpha^{(k)}Ap^{(k)} \in \mathcal{K}_{k+2}(r^{(0)})$ 
\begin{align*}
^{(\ast \ast \ast)}\Rightarrow& p^{(k+1)}=r^{(k+1)}-\beta^{(k)}p^{(k)} \in \mathcal{K}_{k+2}(r^{(0)}) \\
\Rightarrow & span \{ p^{(0)},\dots p^{(k+1)} \} \subset \mathcal{K}_{k+2}(r^{(0)})
\end{align*}
$'\supset '$\\
IV $span \{p^{(0)},\dots p^{(k)}\} = \mathcal{K}_{k+1}(r^{(0)})$ \\
IS: IV $\Rightarrow A^kr^{(0)} \in span \{ p^{(0)},\dots p^{(k)} \}$ \\
\begin{align*}
^{(\ast \ast)} \Rightarrow & A^{k+1}r^{(0)} \in span \{ r^{(0)},\dots , r^{(k+1)} \} = span \{ p^{(0)},\dots p^{(k+1)} \} \\
\Rightarrow & '\supset '
\end{align*}
\end{proof}
4) $^{2) + 3)} \Rightarrow \, x^{(k+1)}-x^{(k)}$ ist die Orthogonalprojektion des Anfangsfehlers $ x-x^{(0)} =: e^{(0)}$ auf den Krylovraum $\mathcal{K}_{k+1}(r^{(0)}$.\\
5) es gilt mit 4) und $e^{(k+1)}=x-x^{(k+1)}$:
\begin{align*}
||e^{(k+1)}||A &= || (x-x^{(0)})-(x^{(k+1)} -x^{(0)} ||_A \\
&= \min_{y \in \mathcal{K}_{k+1}(r^{(0)})} ||x-x^{(0)} - y ||_A = \min_{y \in \mathcal{K}_{k+1}(r^{(0)})} ||e^{(0)} - y ||_A 
\end{align*}
Da $r^{(0)} =A(x-x^{(0)})$=Ae^{(0)}$  lässt sich ein bel. $y \in \mathcal{K}_{k+1}(r^{(0)})$ schreiben als:
\[ y= \sum_{j=0}^k \tilde \gamma_j A^jr^{(0)} = \sum_{j=1}^{k+1}\gamma_j A^j e^{(0)} = \tilde p (A)e^{(0)}, \,  p \in \mathcal{P}_{k+1} \]

JERO

Somit gilt die rekursive Darstellung
\[ T_0(x)=1,\, T_1(x)=x,\, T_{k+1}(x)=2xT_k (x) - T_{k-1}(x),\, k=1,2,\dots \]
$ \Rightarrow T_k \in \mathcal{P}_k$ \\
8) Es gilt auch die Darstellung
\[ T_K (x) =\cosh (k\cdot arccosh (x))\text{ für } x \geq 1,\, T_0(x)=1,\, T_1(x)=x \]
Für den Rest muss man die Rekursionsformel anwenden:\\
Setze für $x \geq 1$: $t:=arccosh(x) = ln (x+\sqrt{x^2-1})$\\
Dann gilt
\[ T_k(x) = cosh (kt) = \frac{1}{2} (e^{kt} + e^{-kt})\geq \frac{1}{2} (e^t)^k = \frac{1}{2} (x+\sqrt{x^2-1})^k \]

9) Wähle nun $q \in \mathcal{P}^*_{k+1}$ wie folgt
\[ q(\lambda) := \frac{T_{k+1}\left( \frac{2\lambda - \lambda_{min} - \lambda_{max}}{\lambda_{min}-\lambda_{max}} \right) }{T_{k+1} \left( \frac{\lambda_{min}+\lambda_{max}}{\lambda_{max} - \lambda_{min}}\right)} \Rightarrow q(0)=1, q\in\mathcal{P}_{k+1} \rightarrow q\in\mathcal{P}^*_{k+1} 
\]
Weiterhin gilt: 
\[\max_{\lambda \in \sigma (A)} |q(\lambda)| \leq \frac{1}{T_{k+1}\left( .......... \right)} \]





